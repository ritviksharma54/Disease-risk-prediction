{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_df = pd.read_csv('/kaggle/input/thapar-summer-school-2024-competition-2/train.csv/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/thapar-summer-school-2024-competition-2/test.csv/test.csv')\n",
    "sample_submission_df = pd.read_csv('/kaggle/input/thapar-summer-school-2024-competition-2/sample_submission (1).csv')\n",
    "\n",
    "# Display the first few rows of the datasets\n",
    "print(\"Train Dataset:\")\n",
    "print(train_df.head())\n",
    "print(\"\\nTest Dataset:\")\n",
    "print(test_df.head())\n",
    "print(\"\\nSample Submission:\")\n",
    "print(sample_submission_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values\n",
    "# Fill missing values in numeric columns with mean\n",
    "numeric_columns = train_df.select_dtypes(include=['number']).columns\n",
    "train_df[numeric_columns] = train_df[numeric_columns].fillna(train_df[numeric_columns].mean())\n",
    "test_df[numeric_columns] = test_df[numeric_columns].fillna(test_df[numeric_columns].mean())\n",
    "\n",
    "# Fill missing values in categorical columns with mode\n",
    "categorical_columns = train_df.select_dtypes(include=['object']).columns\n",
    "categorical_columns = categorical_columns.drop('NObeyesdad')\n",
    "train_df[categorical_columns] = train_df[categorical_columns].fillna(train_df[categorical_columns].mode().iloc[0])\n",
    "test_df[categorical_columns] = test_df[categorical_columns].fillna(test_df[categorical_columns].mode().iloc[0])\n",
    "\n",
    "# Combine train and test data for consistent label encoding\n",
    "combined_df = pd.concat([train_df[categorical_columns], test_df[categorical_columns]])\n",
    "\n",
    "# Encoding categorical variables\n",
    "label_encoders = {}\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    combined_df[col] = le.fit_transform(combined_df[col])\n",
    "    train_df[col] = combined_df[:len(train_df)][col]\n",
    "    test_df[col] = combined_df[len(train_df):][col]\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Encode the target variable\n",
    "target_le = LabelEncoder()\n",
    "train_df['NObeyesdad'] = target_le.fit_transform(train_df['NObeyesdad'])\n",
    "label_encoders['NObeyesdad'] = target_le\n",
    "\n",
    "# Splitting features and target variable from training data\n",
    "X_train = train_df.drop(columns=['NObeyesdad'])\n",
    "y_train = train_df['NObeyesdad']\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_split = scaler.fit_transform(X_train_split)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "test_df = scaler.transform(test_df)\n",
    "\n",
    "# Initialize the models\n",
    "xgb_model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "lgb_model = LGBMClassifier(random_state=42,verbosity=-1)\n",
    "\n",
    "# Create a voting classifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('xgb', xgb_model),\n",
    "        ('rf', rf_model),\n",
    "        ('lgb', lgb_model)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# Train the voting classifier\n",
    "voting_clf.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Validate the model\n",
    "y_val_pred = voting_clf.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f'Validation Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Train the voting classifier on the entire training set\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = voting_clf.predict(test_df)\n",
    "\n",
    "# Map predictions back to original labels\n",
    "test_predictions_labels = label_encoders['NObeyesdad'].inverse_transform(test_predictions)\n",
    "\n",
    "# Prepare the submission file\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': sample_submission_df['id'],\n",
    "    'NObeyesdad': test_predictions_labels\n",
    "})\n",
    "\n",
    "# Save the submission file\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "print(\"Submission file created successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
